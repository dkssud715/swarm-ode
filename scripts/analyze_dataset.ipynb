{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c29ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Optional\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mh5py\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spatial_density_heatmap(trajectories: List[np.ndarray], grid_size: Tuple[int, int], \n",
    "                                    cell_size: float = 1.0) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Calculate smooth spatial density heatmap\"\"\"\n",
    "    # Create density grid\n",
    "    x_bins = np.arange(0, grid_size[1] + cell_size, cell_size)\n",
    "    y_bins = np.arange(0, grid_size[0] + cell_size, cell_size)\n",
    "    \n",
    "    density_grid = np.zeros((len(y_bins)-1, len(x_bins)-1))\n",
    "    \n",
    "    # Accumulate agent positions across all trajectories and timesteps\n",
    "    for trajectory in trajectories:\n",
    "        for timestep_positions in trajectory:\n",
    "            for pos in timestep_positions:\n",
    "                x, y = pos[0], pos[1]\n",
    "                # Find which bin this position belongs to\n",
    "                x_idx = np.digitize(x, x_bins) - 1\n",
    "                y_idx = np.digitize(y, y_bins) - 1\n",
    "                \n",
    "                # Make sure indices are within bounds\n",
    "                if 0 <= x_idx < len(x_bins)-1 and 0 <= y_idx < len(y_bins)-1:\n",
    "                    density_grid[y_idx, x_idx] += 1\n",
    "    \n",
    "    # Normalize by total timesteps to get density\n",
    "    total_timesteps = sum(len(traj) for traj in trajectories)\n",
    "    density_grid = density_grid / total_timesteps if total_timesteps > 0 else density_grid\n",
    "    \n",
    "    # Create coordinate grids for plotting\n",
    "    X, Y = np.meshgrid(x_bins[:-1] + cell_size/2, y_bins[:-1] + cell_size/2)\n",
    "    \n",
    "    return density_grid, X, Y\n",
    "\n",
    "def calculate_temporal_density_evolution(trajectories: List[np.ndarray], grid_size: Tuple[int, int], \n",
    "                                       time_windows: int = 10, cell_size: float = 2.0) -> List[np.ndarray]:\n",
    "    \"\"\"Calculate how density evolves over time\"\"\"\n",
    "    if not trajectories:\n",
    "        return []\n",
    "    \n",
    "    max_episode_length = max(len(traj) for traj in trajectories)\n",
    "    window_size = max_episode_length // time_windows\n",
    "    \n",
    "    density_evolution = []\n",
    "    \n",
    "    for window_idx in range(time_windows):\n",
    "        start_time = window_idx * window_size\n",
    "        end_time = min((window_idx + 1) * window_size, max_episode_length)\n",
    "        \n",
    "        # Extract trajectories for this time window\n",
    "        windowed_trajectories = []\n",
    "        for trajectory in trajectories:\n",
    "            if len(trajectory) > start_time:\n",
    "                window_traj = trajectory[start_time:min(end_time, len(trajectory))]\n",
    "                if len(window_traj) > 0:\n",
    "                    windowed_trajectories.append(window_traj)\n",
    "        \n",
    "        # Calculate density for this window\n",
    "        if windowed_trajectories:\n",
    "            density_grid, _, _ = calculate_spatial_density_heatmap(\n",
    "                windowed_trajectories, grid_size, cell_size\n",
    "            )\n",
    "            density_evolution.append(density_grid)\n",
    "    \n",
    "    return density_evolution\n",
    "\n",
    "def plot_spatial_density_heatmaps(datasets_analysis: List[Dict], save_path: Optional[str] = None):\n",
    "    \"\"\"Plot spatial density heatmaps for multiple datasets\"\"\"\n",
    "    num_datasets = len(datasets_analysis)\n",
    "    fig, axes = plt.subplots(2, num_datasets, figsize=(5*num_datasets, 10))\n",
    "    \n",
    "    if num_datasets == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, analysis in enumerate(datasets_analysis):\n",
    "        density_heatmap = analysis['density_heatmap']\n",
    "        X, Y = analysis['heatmap_coords']\n",
    "        dataset_name = analysis['dataset_name']\n",
    "        \n",
    "        # Regular heatmap\n",
    "        im1 = axes[0, i].contourf(X, Y, density_heatmap, levels=20, cmap='YlOrRd')\n",
    "        axes[0, i].set_title(f'{dataset_name}\\nDensity Heatmap')\n",
    "        axes[0, i].set_xlabel('X Position')\n",
    "        axes[0, i].set_ylabel('Y Position')\n",
    "        fig.colorbar(im1, ax=axes[0, i], label='Density')\n",
    "        \n",
    "        # Smoothed contour plot\n",
    "        im2 = axes[1, i].contour(X, Y, density_heatmap, levels=10, colors='black', alpha=0.6)\n",
    "        axes[1, i].contourf(X, Y, density_heatmap, levels=20, cmap='viridis', alpha=0.8)\n",
    "        axes[1, i].set_title(f'{dataset_name}\\nSmooth Density Contours')\n",
    "        axes[1, i].set_xlabel('X Position')\n",
    "        axes[1, i].set_ylabel('Y Position')\n",
    "        \n",
    "        # Add density statistics as text\n",
    "        stats_text = f'Max: {analysis[\"max_local_density\"]:.3f}\\n'\n",
    "        stats_text += f'Concentration: {analysis[\"density_concentration\"]:.3f}\\n'\n",
    "        stats_text += f'Effective: {analysis[\"effective_density\"]:.3f}'\n",
    "        axes[1, i].text(0.02, 0.98, stats_text, transform=axes[1, i].transAxes, \n",
    "                       verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_temporal_density_evolution(h5_file_path: str, dataset_name: str, \n",
    "                                  time_windows: int = 6, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot how density evolves over time within episodes\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path, max_episodes=50)\n",
    "    density_evolution = calculate_temporal_density_evolution(trajectories, metadata['grid_size'], time_windows)\n",
    "    \n",
    "    if not density_evolution:\n",
    "        print(\"No density evolution data available\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, density_grid in enumerate(density_evolution[:6]):  # Show first 6 time windows\n",
    "        if i < len(axes):\n",
    "            im = axes[i].imshow(density_grid, cmap='YlOrRd', origin='lower')\n",
    "            axes[i].set_title(f'Time Window {i+1}')\n",
    "            axes[i].set_xlabel('X Position')\n",
    "            axes[i].set_ylabel('Y Position')\n",
    "            plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(density_evolution), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.suptitle(f'{dataset_name}: Density Evolution Over Time', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def load_dataset_metadata(h5_file_path: str) -> Dict:\n",
    "    \"\"\"Load basic metadata from HDF5 file\"\"\"\n",
    "    with h5py.File(h5_file_path, 'r') as f:\n",
    "        first_episode = next(iter([key for key in f.keys() if key.startswith('episode_')]))\n",
    "        metadata_group = f[first_episode]['metadata']\n",
    "        \n",
    "        return {\n",
    "            'num_agvs': metadata_group.attrs['num_agvs'],\n",
    "            'num_pickers': metadata_group.attrs['num_pickers'],\n",
    "            'grid_size': metadata_group.attrs['grid_size'],\n",
    "            'num_episodes': len([key for key in f.keys() if key.startswith('episode_')])\n",
    "        }\n",
    "\n",
    "def extract_positions_from_observations(observations: np.ndarray, num_agvs: int, num_pickers: int) -> np.ndarray:\n",
    "    \"\"\"Extract agent positions from observations\"\"\"\n",
    "    positions = []\n",
    "    \n",
    "    for i, obs in enumerate(observations):\n",
    "        if i < num_agvs:  # AGV agent\n",
    "            y, x = obs[3], obs[4]\n",
    "        else:  # Picker agent\n",
    "            y, x = obs[0], obs[1]\n",
    "        positions.append([x, y])  # Note: switching to (x, y) format\n",
    "    \n",
    "    return np.array(positions)\n",
    "\n",
    "def load_episode_trajectories(h5_file_path: str, max_episodes: Optional[int] = None) -> Tuple[List[np.ndarray], Dict]:\n",
    "    \"\"\"Load all trajectories from episodes\"\"\"\n",
    "    trajectories = []\n",
    "    metadata = load_dataset_metadata(h5_file_path)\n",
    "    \n",
    "    with h5py.File(h5_file_path, 'r') as f:\n",
    "        episode_keys = [key for key in f.keys() if key.startswith('episode_')]\n",
    "        episode_keys = sorted(episode_keys)[:max_episodes] if max_episodes else episode_keys\n",
    "        \n",
    "        for episode_key in episode_keys:\n",
    "            episode_group = f[episode_key]\n",
    "            steps_group = episode_group['steps']\n",
    "            \n",
    "            episode_trajectory = []\n",
    "            for step_name in sorted(steps_group.keys()):\n",
    "                step_group = steps_group[step_name]\n",
    "                observations = step_group['observations'][:]\n",
    "                positions = extract_positions_from_observations(\n",
    "                    observations, metadata['num_agvs'], metadata['num_pickers']\n",
    "                )\n",
    "                episode_trajectory.append(positions)\n",
    "            \n",
    "            if episode_trajectory:\n",
    "                trajectories.append(np.array(episode_trajectory))  # [steps, agents, 2]\n",
    "    \n",
    "    return trajectories, metadata\n",
    "\n",
    "# 1. Density and Complexity Analysis\n",
    "def analyze_density_and_complexity(h5_file_path: str, dataset_name: str) -> Dict:\n",
    "    \"\"\"Analyze agent density and interaction complexity\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path)\n",
    "    \n",
    "    grid_size = metadata['grid_size']\n",
    "    num_agents = metadata['num_agvs'] + metadata['num_pickers']\n",
    "    \n",
    "    # Agent density\n",
    "    total_area = grid_size[0] * grid_size[1]\n",
    "    agent_density = num_agents / total_area\n",
    "    \n",
    "    # Interaction complexity metrics\n",
    "    collision_counts = []\n",
    "    avg_distances = []\n",
    "    path_lengths = []\n",
    "    \n",
    "    for trajectory in trajectories:\n",
    "        # Calculate average inter-agent distances\n",
    "        distances_per_step = []\n",
    "        for step_positions in trajectory:\n",
    "            if len(step_positions) > 1:\n",
    "                distances = pdist(step_positions)\n",
    "                distances_per_step.append(np.mean(distances))\n",
    "        \n",
    "        if distances_per_step:\n",
    "            avg_distances.append(np.mean(distances_per_step))\n",
    "        \n",
    "        # Calculate path lengths for each agent\n",
    "        for agent_idx in range(num_agents):\n",
    "            agent_path = trajectory[:, agent_idx, :]\n",
    "            path_length = np.sum(np.linalg.norm(np.diff(agent_path, axis=0), axis=1))\n",
    "            path_lengths.append(path_length)\n",
    "        \n",
    "        # Count potential collisions (agents within distance threshold)\n",
    "        collision_count = 0\n",
    "        for step_positions in trajectory:\n",
    "            if len(step_positions) > 1:\n",
    "                distances = squareform(pdist(step_positions))\n",
    "                # Count pairs with distance < 1.5 (collision threshold)\n",
    "                collision_count += np.sum((distances < 1.5) & (distances > 0)) / 2\n",
    "        collision_counts.append(collision_count)\n",
    "    \n",
    "    return {\n",
    "        'dataset_name': dataset_name,\n",
    "        'agent_density': agent_density,\n",
    "        'avg_inter_agent_distance': np.mean(avg_distances),\n",
    "        'avg_collision_count': np.mean(collision_counts),\n",
    "        'avg_path_length': np.mean(path_lengths),\n",
    "        'grid_size': grid_size,\n",
    "        'num_agents': num_agents,\n",
    "        'num_episodes': len(trajectories)\n",
    "    }\n",
    "\n",
    "# 2. Trajectory Characteristics Analysis\n",
    "def analyze_trajectory_characteristics(h5_file_path: str) -> Dict:\n",
    "    \"\"\"Analyze speed distribution and path diversity\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path)\n",
    "    \n",
    "    all_speeds = []\n",
    "    all_accelerations = []\n",
    "    path_diversities = []\n",
    "    \n",
    "    for trajectory in trajectories:\n",
    "        # Path diversity (using variance of positions)\n",
    "        all_positions = trajectory.reshape(-1, 2)\n",
    "        position_variance = np.var(all_positions, axis=0)\n",
    "        path_diversities.append(np.mean(position_variance))\n",
    "    \n",
    "    return {\n",
    "        'path_diversity_mean': np.mean(path_diversities),\n",
    "        'path_diversity_std': np.std(path_diversities)\n",
    "    }\n",
    "\n",
    "# 3. Visualization Functions\n",
    "def plot_density_comparison(datasets_analysis: List[Dict], save_path: Optional[str] = None):\n",
    "    \"\"\"Plot density comparison across datasets\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    dataset_names = [d['dataset_name'] for d in datasets_analysis]\n",
    "    \n",
    "    # Agent density\n",
    "    densities = [d['agent_density'] for d in datasets_analysis]\n",
    "    axes[0,0].bar(dataset_names, densities)\n",
    "    axes[0,0].set_title('Agent Density')\n",
    "    axes[0,0].set_ylabel('Agents per Grid Cell')\n",
    "    \n",
    "    # Average inter-agent distance\n",
    "    distances = [d['avg_inter_agent_distance'] for d in datasets_analysis]\n",
    "    axes[0,1].bar(dataset_names, distances)\n",
    "    axes[0,1].set_title('Average Inter-Agent Distance')\n",
    "    axes[0,1].set_ylabel('Distance')\n",
    "    \n",
    "    # Collision counts\n",
    "    collisions = [d['avg_collision_count'] for d in datasets_analysis]\n",
    "    axes[1,0].bar(dataset_names, collisions)\n",
    "    axes[1,0].set_title('Average Collision Count per Episode')\n",
    "    axes[1,0].set_ylabel('Collision Count')\n",
    "    \n",
    "    # Path lengths\n",
    "    path_lengths = [d['avg_path_length'] for d in datasets_analysis]\n",
    "    axes[1,1].bar(dataset_names, path_lengths)\n",
    "    axes[1,1].set_title('Average Path Length')\n",
    "    axes[1,1].set_ylabel('Path Length')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_initial_position_distribution(h5_file_path: str, max_episodes: int = 50, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot initial position distribution of agents\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path, max_episodes)\n",
    "    \n",
    "    # Collect all initial positions\n",
    "    initial_positions = []\n",
    "    for trajectory in trajectories:\n",
    "        initial_positions.append(trajectory[0])  # First step positions\n",
    "    \n",
    "    initial_positions = np.vstack(initial_positions)  # [total_agents, 2]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(initial_positions[:, 0], initial_positions[:, 1], alpha=0.6, s=20)\n",
    "    plt.title(f'Initial Position Distribution (n={len(trajectories)} episodes)')\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_trajectory_examples(h5_file_path: str, num_episodes: int = 3, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot example trajectories from episodes\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path, num_episodes)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_episodes, figsize=(5*num_episodes, 5))\n",
    "    if num_episodes == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, metadata['num_agvs'] + metadata['num_pickers']))\n",
    "    \n",
    "    for ep_idx, trajectory in enumerate(trajectories):\n",
    "        ax = axes[ep_idx]\n",
    "        \n",
    "        # Plot each agent's trajectory\n",
    "        for agent_idx in range(metadata['num_agvs'] + metadata['num_pickers']):\n",
    "            agent_path = trajectory[:, agent_idx, :]\n",
    "            \n",
    "            # Plot trajectory\n",
    "            ax.plot(agent_path[:, 0], agent_path[:, 1], \n",
    "                   color=colors[agent_idx], alpha=0.7, linewidth=2)\n",
    "            \n",
    "            # Mark start and end\n",
    "            ax.scatter(agent_path[0, 0], agent_path[0, 1], \n",
    "                      color=colors[agent_idx], marker='o', s=100, edgecolor='black')\n",
    "            ax.scatter(agent_path[-1, 0], agent_path[-1, 1], \n",
    "                      color=colors[agent_idx], marker='s', s=100, edgecolor='black')\n",
    "        \n",
    "        ax.set_title(f'Episode {ep_idx + 1}')\n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend([f'Agent {i}' for i in range(metadata['num_agvs'] + metadata['num_pickers'])], \n",
    "                 bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Main analysis function\n",
    "def analyze_datasets(dataset_paths: Dict[str, str], output_dir: str = \"./analysis_results/\"):\n",
    "    \"\"\"Complete analysis of multiple datasets with enhanced spatial density\"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Density and complexity analysis\n",
    "    density_results = []\n",
    "    for name, path in dataset_paths.items():\n",
    "        result = analyze_density_and_complexity(path, name)\n",
    "        density_results.append(result)\n",
    "        print(f\"Dataset: {name}\")\n",
    "        print(f\"  Traditional Density: {result['agent_density']:.4f}\")\n",
    "        print(f\"  Effective Density: {result['effective_density']:.4f}\")\n",
    "        print(f\"  Density Concentration: {result['density_concentration']:.4f}\")\n",
    "        print(f\"  Max Local Density: {result['max_local_density']:.4f}\")\n",
    "        print(f\"  Avg Inter-Agent Distance: {result['avg_inter_agent_distance']:.2f}\")\n",
    "        print(f\"  Avg Collision Count: {result['avg_collision_count']:.2f}\")\n",
    "        print(f\"  Avg Path Length: {result['avg_path_length']:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    # 2. Trajectory characteristics\n",
    "    traj_chars = []\n",
    "    for name, path in dataset_paths.items():\n",
    "        chars = analyze_trajectory_characteristics(path)\n",
    "        traj_chars.append(chars)\n",
    "    \n",
    "    # 3. Generate enhanced visualizations\n",
    "    plot_density_comparison(density_results, f\"{output_dir}/density_comparison.png\")\n",
    "    plot_spatial_density_heatmaps(density_results, f\"{output_dir}/spatial_density_heatmaps.png\")\n",
    "    \n",
    "    # Individual dataset visualizations\n",
    "    for name, path in dataset_paths.items():\n",
    "        plot_initial_position_distribution(path, save_path=f\"{output_dir}/{name}_initial_positions.png\")\n",
    "        plot_trajectory_examples(path, save_path=f\"{output_dir}/{name}_trajectory_examples.png\")\n",
    "        plot_temporal_density_evolution(path, name, save_path=f\"{output_dir}/{name}_temporal_density.png\")\n",
    "    \n",
    "    return density_results, traj_chars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnode_tarware",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
