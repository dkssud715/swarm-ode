{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c29ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Optional\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mh5py\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_metadata(h5_file_path: str) -> Dict:\n",
    "    \"\"\"Load basic metadata from HDF5 file\"\"\"\n",
    "    with h5py.File(h5_file_path, 'r') as f:\n",
    "        first_episode = next(iter([key for key in f.keys() if key.startswith('episode_')]))\n",
    "        metadata_group = f[first_episode]['metadata']\n",
    "        \n",
    "        return {\n",
    "            'num_agvs': metadata_group.attrs['num_agvs'],\n",
    "            'num_pickers': metadata_group.attrs['num_pickers'],\n",
    "            'grid_size': metadata_group.attrs['grid_size'],\n",
    "            'num_episodes': len([key for key in f.keys() if key.startswith('episode_')])\n",
    "        }\n",
    "\n",
    "def extract_positions_from_observations(observations: np.ndarray, num_agvs: int, num_pickers: int) -> np.ndarray:\n",
    "    \"\"\"Extract agent positions from observations\"\"\"\n",
    "    positions = []\n",
    "    \n",
    "    for i, obs in enumerate(observations):\n",
    "        if i < num_agvs:  # AGV agent\n",
    "            y, x = obs[3], obs[4]\n",
    "        else:  # Picker agent\n",
    "            y, x = obs[0], obs[1]\n",
    "        positions.append([x, y])  # Note: switching to (x, y) format\n",
    "    \n",
    "    return np.array(positions)\n",
    "\n",
    "def load_episode_trajectories(h5_file_path: str, max_episodes: Optional[int] = None) -> Tuple[List[np.ndarray], Dict]:\n",
    "    \"\"\"Load all trajectories from episodes\"\"\"\n",
    "    trajectories = []\n",
    "    metadata = load_dataset_metadata(h5_file_path)\n",
    "    \n",
    "    with h5py.File(h5_file_path, 'r') as f:\n",
    "        episode_keys = [key for key in f.keys() if key.startswith('episode_')]\n",
    "        episode_keys = sorted(episode_keys)[:max_episodes] if max_episodes else episode_keys\n",
    "        \n",
    "        for episode_key in episode_keys:\n",
    "            episode_group = f[episode_key]\n",
    "            steps_group = episode_group['steps']\n",
    "            \n",
    "            episode_trajectory = []\n",
    "            for step_name in sorted(steps_group.keys()):\n",
    "                step_group = steps_group[step_name]\n",
    "                observations = step_group['observations'][:]\n",
    "                positions = extract_positions_from_observations(\n",
    "                    observations, metadata['num_agvs'], metadata['num_pickers']\n",
    "                )\n",
    "                episode_trajectory.append(positions)\n",
    "            \n",
    "            if episode_trajectory:\n",
    "                trajectories.append(np.array(episode_trajectory))  # [steps, agents, 2]\n",
    "    \n",
    "    return trajectories, metadata\n",
    "\n",
    "# 1. Density and Complexity Analysis\n",
    "def analyze_density_and_complexity(h5_file_path: str, dataset_name: str) -> Dict:\n",
    "    \"\"\"Analyze agent density and interaction complexity\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path)\n",
    "    \n",
    "    grid_size = metadata['grid_size']\n",
    "    num_agents = metadata['num_agvs'] + metadata['num_pickers']\n",
    "    \n",
    "    # Agent density\n",
    "    total_area = grid_size[0] * grid_size[1]\n",
    "    agent_density = num_agents / total_area\n",
    "    \n",
    "    # Interaction complexity metrics\n",
    "    collision_counts = []\n",
    "    avg_distances = []\n",
    "    path_lengths = []\n",
    "    \n",
    "    for trajectory in trajectories:\n",
    "        # Calculate average inter-agent distances\n",
    "        distances_per_step = []\n",
    "        for step_positions in trajectory:\n",
    "            if len(step_positions) > 1:\n",
    "                distances = pdist(step_positions)\n",
    "                distances_per_step.append(np.mean(distances))\n",
    "        \n",
    "        if distances_per_step:\n",
    "            avg_distances.append(np.mean(distances_per_step))\n",
    "        \n",
    "        # Calculate path lengths for each agent\n",
    "        for agent_idx in range(num_agents):\n",
    "            agent_path = trajectory[:, agent_idx, :]\n",
    "            path_length = np.sum(np.linalg.norm(np.diff(agent_path, axis=0), axis=1))\n",
    "            path_lengths.append(path_length)\n",
    "        \n",
    "        # Count potential collisions (agents within distance threshold)\n",
    "        collision_count = 0\n",
    "        for step_positions in trajectory:\n",
    "            if len(step_positions) > 1:\n",
    "                distances = squareform(pdist(step_positions))\n",
    "                # Count pairs with distance < 1.5 (collision threshold)\n",
    "                collision_count += np.sum((distances < 1.5) & (distances > 0)) / 2\n",
    "        collision_counts.append(collision_count)\n",
    "    \n",
    "    return {\n",
    "        'dataset_name': dataset_name,\n",
    "        'agent_density': agent_density,\n",
    "        'avg_inter_agent_distance': np.mean(avg_distances),\n",
    "        'avg_collision_count': np.mean(collision_counts),\n",
    "        'avg_path_length': np.mean(path_lengths),\n",
    "        'grid_size': grid_size,\n",
    "        'num_agents': num_agents,\n",
    "        'num_episodes': len(trajectories)\n",
    "    }\n",
    "\n",
    "# 2. Trajectory Characteristics Analysis\n",
    "def analyze_trajectory_characteristics(h5_file_path: str) -> Dict:\n",
    "    \"\"\"Analyze speed distribution and path diversity\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path)\n",
    "    \n",
    "    all_speeds = []\n",
    "    all_accelerations = []\n",
    "    path_diversities = []\n",
    "    \n",
    "    for trajectory in trajectories:\n",
    "        # Path diversity (using variance of positions)\n",
    "        all_positions = trajectory.reshape(-1, 2)\n",
    "        position_variance = np.var(all_positions, axis=0)\n",
    "        path_diversities.append(np.mean(position_variance))\n",
    "    \n",
    "    return {\n",
    "        'path_diversity_mean': np.mean(path_diversities),\n",
    "        'path_diversity_std': np.std(path_diversities)\n",
    "    }\n",
    "\n",
    "# 3. Visualization Functions\n",
    "def plot_density_comparison(datasets_analysis: List[Dict], save_path: Optional[str] = None):\n",
    "    \"\"\"Plot density comparison across datasets\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    dataset_names = [d['dataset_name'] for d in datasets_analysis]\n",
    "    \n",
    "    # Agent density\n",
    "    densities = [d['agent_density'] for d in datasets_analysis]\n",
    "    axes[0,0].bar(dataset_names, densities)\n",
    "    axes[0,0].set_title('Agent Density')\n",
    "    axes[0,0].set_ylabel('Agents per Grid Cell')\n",
    "    \n",
    "    # Average inter-agent distance\n",
    "    distances = [d['avg_inter_agent_distance'] for d in datasets_analysis]\n",
    "    axes[0,1].bar(dataset_names, distances)\n",
    "    axes[0,1].set_title('Average Inter-Agent Distance')\n",
    "    axes[0,1].set_ylabel('Distance')\n",
    "    \n",
    "    # Collision counts\n",
    "    collisions = [d['avg_collision_count'] for d in datasets_analysis]\n",
    "    axes[1,0].bar(dataset_names, collisions)\n",
    "    axes[1,0].set_title('Average Collision Count per Episode')\n",
    "    axes[1,0].set_ylabel('Collision Count')\n",
    "    \n",
    "    # Path lengths\n",
    "    path_lengths = [d['avg_path_length'] for d in datasets_analysis]\n",
    "    axes[1,1].bar(dataset_names, path_lengths)\n",
    "    axes[1,1].set_title('Average Path Length')\n",
    "    axes[1,1].set_ylabel('Path Length')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_initial_position_distribution(h5_file_path: str, max_episodes: int = 50, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot initial position distribution of agents\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path, max_episodes)\n",
    "    \n",
    "    # Collect all initial positions\n",
    "    initial_positions = []\n",
    "    for trajectory in trajectories:\n",
    "        initial_positions.append(trajectory[0])  # First step positions\n",
    "    \n",
    "    initial_positions = np.vstack(initial_positions)  # [total_agents, 2]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(initial_positions[:, 0], initial_positions[:, 1], alpha=0.6, s=20)\n",
    "    plt.title(f'Initial Position Distribution (n={len(trajectories)} episodes)')\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_trajectory_examples(h5_file_path: str, num_episodes: int = 3, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot example trajectories from episodes\"\"\"\n",
    "    trajectories, metadata = load_episode_trajectories(h5_file_path, num_episodes)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_episodes, figsize=(5*num_episodes, 5))\n",
    "    if num_episodes == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, metadata['num_agvs'] + metadata['num_pickers']))\n",
    "    \n",
    "    for ep_idx, trajectory in enumerate(trajectories):\n",
    "        ax = axes[ep_idx]\n",
    "        \n",
    "        # Plot each agent's trajectory\n",
    "        for agent_idx in range(metadata['num_agvs'] + metadata['num_pickers']):\n",
    "            agent_path = trajectory[:, agent_idx, :]\n",
    "            \n",
    "            # Plot trajectory\n",
    "            ax.plot(agent_path[:, 0], agent_path[:, 1], \n",
    "                   color=colors[agent_idx], alpha=0.7, linewidth=2)\n",
    "            \n",
    "            # Mark start and end\n",
    "            ax.scatter(agent_path[0, 0], agent_path[0, 1], \n",
    "                      color=colors[agent_idx], marker='o', s=100, edgecolor='black')\n",
    "            ax.scatter(agent_path[-1, 0], agent_path[-1, 1], \n",
    "                      color=colors[agent_idx], marker='s', s=100, edgecolor='black')\n",
    "        \n",
    "        ax.set_title(f'Episode {ep_idx + 1}')\n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend([f'Agent {i}' for i in range(metadata['num_agvs'] + metadata['num_pickers'])], \n",
    "                 bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Main analysis function\n",
    "def analyze_datasets(dataset_paths: Dict[str, str], output_dir: str = \"./analysis_results/\"):\n",
    "    \"\"\"Complete analysis of multiple datasets\"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Density and complexity analysis\n",
    "    density_results = []\n",
    "    for name, path in dataset_paths.items():\n",
    "        result = analyze_density_and_complexity(path, name)\n",
    "        density_results.append(result)\n",
    "        print(f\"Dataset: {name}\")\n",
    "        print(f\"  Agent Density: {result['agent_density']:.4f}\")\n",
    "        print(f\"  Avg Inter-Agent Distance: {result['avg_inter_agent_distance']:.2f}\")\n",
    "        print(f\"  Avg Collision Count: {result['avg_collision_count']:.2f}\")\n",
    "        print(f\"  Avg Path Length: {result['avg_path_length']:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    # 2. Trajectory characteristics\n",
    "    traj_chars = []\n",
    "    for name, path in dataset_paths.items():\n",
    "        chars = analyze_trajectory_characteristics(path)\n",
    "        traj_chars.append(chars)\n",
    "    \n",
    "    # 3. Generate visualizations\n",
    "    plot_density_comparison(density_results, f\"{output_dir}/density_comparison.png\")\n",
    "    \n",
    "    # Individual dataset visualizations\n",
    "    for name, path in dataset_paths.items():\n",
    "        plot_initial_position_distribution(path, save_path=f\"{output_dir}/{name}_initial_positions.png\")\n",
    "        plot_trajectory_examples(path, save_path=f\"{output_dir}/{name}_trajectory_examples.png\")\n",
    "    \n",
    "    return density_results, traj_chars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnode_tarware",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
