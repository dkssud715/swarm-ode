{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24274ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from torch_geometric.data import Batch\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from dtaidistance import dtw\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path: str, model_class, **model_kwargs):\n",
    "    \"\"\"Load trained GraphODE model\"\"\"\n",
    "    model = model_class(**model_kwargs)\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict_trajectories(model, test_loader, device='cpu', max_batches=None):\n",
    "    \"\"\"Generate predictions for test dataset\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_batch_info = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if max_batches and batch_idx >= max_batches:\n",
    "                break\n",
    "                \n",
    "            batch.graphs = batch.graphs.to(device)\n",
    "            batch.next_positions = batch.next_positions.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            time_span = torch.tensor([0., 1.], device=device)\n",
    "            result = model(batch.graphs, time_span)\n",
    "            pred_next_positions = result['trajectories'][1]  # t=1 predictions\n",
    "            \n",
    "            # Store results\n",
    "            all_predictions.append(pred_next_positions.cpu().numpy())\n",
    "            all_targets.append(batch.next_positions.view(-1, 2).cpu().numpy())\n",
    "            all_batch_info.append({\n",
    "                'batch_size': batch.graphs.batch.max().item() + 1,\n",
    "                'nodes_per_graph': torch.bincount(batch.graphs.batch).cpu().numpy()\n",
    "            })\n",
    "    \n",
    "    return all_predictions, all_targets, all_batch_info\n",
    "\n",
    "def calculate_position_error_metrics(predictions: List[np.ndarray], targets: List[np.ndarray]) -> Dict:\n",
    "    \"\"\"Calculate intuitive position error metrics\"\"\"\n",
    "    all_pred = np.vstack(predictions)\n",
    "    all_target = np.vstack(targets)\n",
    "    \n",
    "    # Euclidean distance errors\n",
    "    position_errors = np.linalg.norm(all_pred - all_target, axis=1)\n",
    "    \n",
    "    # Direction errors (angle between predicted and actual movement)\n",
    "    direction_errors = []\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        if len(pred) > 1:\n",
    "            pred_directions = pred[1:] - pred[:-1]\n",
    "            target_directions = target[1:] - target[:-1]\n",
    "            \n",
    "            # Calculate angle between vectors\n",
    "            for pd, td in zip(pred_directions, target_directions):\n",
    "                if np.linalg.norm(pd) > 0 and np.linalg.norm(td) > 0:\n",
    "                    cos_angle = np.dot(pd, td) / (np.linalg.norm(pd) * np.linalg.norm(td))\n",
    "                    cos_angle = np.clip(cos_angle, -1, 1)  # Handle numerical errors\n",
    "                    angle_error = np.arccos(cos_angle) * 180 / np.pi\n",
    "                    direction_errors.append(angle_error)\n",
    "    \n",
    "    return {\n",
    "        'mean_position_error': np.mean(position_errors),\n",
    "        'std_position_error': np.std(position_errors),\n",
    "        'median_position_error': np.median(position_errors),\n",
    "        'max_position_error': np.max(position_errors),\n",
    "        'position_errors': position_errors,\n",
    "        'mean_direction_error': np.mean(direction_errors) if direction_errors else 0,\n",
    "        'direction_errors': direction_errors\n",
    "    }\n",
    "\n",
    "def calculate_success_rates(predictions: List[np.ndarray], targets: List[np.ndarray], \n",
    "                          tolerance_levels: List[float] = [0.5, 1.0, 1.5, 2.0]) -> Dict:\n",
    "    \"\"\"Calculate success rates at different tolerance levels\"\"\"\n",
    "    all_pred = np.vstack(predictions)\n",
    "    all_target = np.vstack(targets)\n",
    "    \n",
    "    position_errors = np.linalg.norm(all_pred - all_target, axis=1)\n",
    "    \n",
    "    success_rates = {}\n",
    "    for tolerance in tolerance_levels:\n",
    "        success_rate = np.mean(position_errors <= tolerance)\n",
    "        success_rates[f'success_rate_{tolerance}'] = success_rate\n",
    "    \n",
    "    return success_rates\n",
    "\n",
    "def multi_step_prediction_accuracy(model, test_loader, num_steps: int = 10, device='cpu'):\n",
    "    \"\"\"Evaluate multi-step prediction accuracy\"\"\"\n",
    "    model.eval()\n",
    "    step_errors = {i: [] for i in range(1, num_steps + 1)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if batch_idx >= 10:  # Limit for computation\n",
    "                break\n",
    "                \n",
    "            current_graphs = batch.graphs.to(device)\n",
    "            \n",
    "            # Auto-regressive prediction\n",
    "            predictions = []\n",
    "            for step in range(num_steps):\n",
    "                time_span = torch.tensor([0., 1.], device=device)\n",
    "                result = model(current_graphs, time_span)\n",
    "                pred_positions = result['trajectories'][1]\n",
    "                predictions.append(pred_positions.cpu().numpy())\n",
    "                \n",
    "                # Update graph for next prediction (simplified)\n",
    "                # In practice, you'd need to update the graph structure properly\n",
    "                \n",
    "            # Compare with ground truth (if available)\n",
    "            # This is a simplified version - you'd need actual multi-step ground truth\n",
    "            \n",
    "    return step_errors\n",
    "\n",
    "def analyze_collision_prediction(predictions: List[np.ndarray], targets: List[np.ndarray], \n",
    "                               batch_info: List[Dict], collision_threshold: float = 1.5) -> Dict:\n",
    "    \"\"\"Analyze collision prediction accuracy\"\"\"\n",
    "    pred_collisions = []\n",
    "    actual_collisions = []\n",
    "    \n",
    "    for pred, target, info in zip(predictions, targets, batch_info):\n",
    "        nodes_per_graph = info['nodes_per_graph']\n",
    "        start_idx = 0\n",
    "        \n",
    "        for graph_nodes in nodes_per_graph:\n",
    "            if graph_nodes <= 1:\n",
    "                start_idx += graph_nodes\n",
    "                continue\n",
    "                \n",
    "            # Extract positions for this graph\n",
    "            graph_pred = pred[start_idx:start_idx + graph_nodes]\n",
    "            graph_target = target[start_idx:start_idx + graph_nodes]\n",
    "            \n",
    "            # Count collisions in predictions\n",
    "            pred_distances = np.linalg.norm(graph_pred[:, None] - graph_pred[None, :], axis=2)\n",
    "            pred_collisions.append(np.sum((pred_distances < collision_threshold) & (pred_distances > 0)) // 2)\n",
    "            \n",
    "            # Count collisions in targets\n",
    "            target_distances = np.linalg.norm(graph_target[:, None] - graph_target[None, :], axis=2)\n",
    "            actual_collisions.append(np.sum((target_distances < collision_threshold) & (target_distances > 0)) // 2)\n",
    "            \n",
    "            start_idx += graph_nodes\n",
    "    \n",
    "    return {\n",
    "        'predicted_collisions': pred_collisions,\n",
    "        'actual_collisions': actual_collisions,\n",
    "        'collision_prediction_mse': np.mean((np.array(pred_collisions) - np.array(actual_collisions)) ** 2),\n",
    "        'collision_prediction_mae': np.mean(np.abs(np.array(pred_collisions) - np.array(actual_collisions)))\n",
    "    }\n",
    "\n",
    "def plot_prediction_accuracy_analysis(error_metrics: Dict, success_rates: Dict, \n",
    "                                    collision_analysis: Dict, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot comprehensive prediction accuracy analysis\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Position error distribution\n",
    "    axes[0,0].hist(error_metrics['position_errors'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].axvline(error_metrics['mean_position_error'], color='red', linestyle='--', \n",
    "                     label=f'Mean: {error_metrics[\"mean_position_error\"]:.2f}')\n",
    "    axes[0,0].axvline(error_metrics['median_position_error'], color='orange', linestyle='--',\n",
    "                     label=f'Median: {error_metrics[\"median_position_error\"]:.2f}')\n",
    "    axes[0,0].set_title('Position Error Distribution')\n",
    "    axes[0,0].set_xlabel('Position Error (grid units)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Success rates at different tolerances\n",
    "    tolerances = [float(k.split('_')[-1]) for k in success_rates.keys()]\n",
    "    rates = list(success_rates.values())\n",
    "    \n",
    "    axes[0,1].bar(tolerances, rates, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[0,1].set_title('Prediction Success Rate by Tolerance')\n",
    "    axes[0,1].set_xlabel('Tolerance (grid units)')\n",
    "    axes[0,1].set_ylabel('Success Rate')\n",
    "    axes[0,1].set_ylim(0, 1)\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add percentage labels on bars\n",
    "    for i, rate in enumerate(rates):\n",
    "        axes[0,1].text(tolerances[i], rate + 0.01, f'{rate:.1%}', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Direction error distribution (if available)\n",
    "    if error_metrics['direction_errors']:\n",
    "        axes[0,2].hist(error_metrics['direction_errors'], bins=30, alpha=0.7, \n",
    "                      color='lightcoral', edgecolor='black')\n",
    "        axes[0,2].axvline(error_metrics['mean_direction_error'], color='red', linestyle='--',\n",
    "                         label=f'Mean: {error_metrics[\"mean_direction_error\"]:.1f}°')\n",
    "        axes[0,2].set_title('Direction Error Distribution')\n",
    "        axes[0,2].set_xlabel('Direction Error (degrees)')\n",
    "        axes[0,2].set_ylabel('Frequency')\n",
    "        axes[0,2].legend()\n",
    "        axes[0,2].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[0,2].text(0.5, 0.5, 'Direction Error\\nNot Available', ha='center', va='center',\n",
    "                      transform=axes[0,2].transAxes, fontsize=12)\n",
    "        axes[0,2].set_title('Direction Error Distribution')\n",
    "    \n",
    "    # 4. Error statistics summary\n",
    "    error_stats = [\n",
    "        error_metrics['mean_position_error'],\n",
    "        error_metrics['median_position_error'],\n",
    "        error_metrics['std_position_error'],\n",
    "        error_metrics['max_position_error']\n",
    "    ]\n",
    "    stat_labels = ['Mean', 'Median', 'Std Dev', 'Max']\n",
    "    \n",
    "    bars = axes[1,0].bar(stat_labels, error_stats, alpha=0.7, color='gold', edgecolor='black')\n",
    "    axes[1,0].set_title('Position Error Statistics')\n",
    "    axes[1,0].set_ylabel('Error (grid units)')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, stat in zip(bars, error_stats):\n",
    "        axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                      f'{stat:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 5. Collision prediction accuracy\n",
    "    pred_collisions = collision_analysis['predicted_collisions']\n",
    "    actual_collisions = collision_analysis['actual_collisions']\n",
    "    \n",
    "    axes[1,1].scatter(actual_collisions, pred_collisions, alpha=0.6, color='purple')\n",
    "    max_collisions = max(max(pred_collisions) if pred_collisions else 0, \n",
    "                        max(actual_collisions) if actual_collisions else 0)\n",
    "    axes[1,1].plot([0, max_collisions], [0, max_collisions], 'r--', label='Perfect Prediction')\n",
    "    axes[1,1].set_title('Collision Prediction Accuracy')\n",
    "    axes[1,1].set_xlabel('Actual Collisions')\n",
    "    axes[1,1].set_ylabel('Predicted Collisions')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Performance summary\n",
    "    summary_text = f\"\"\"Model Performance Summary\n",
    "    \n",
    "Position Accuracy:\n",
    "• Mean Error: {error_metrics['mean_position_error']:.2f} units\n",
    "• Success Rate (≤1.0): {success_rates.get('success_rate_1.0', 0):.1%}\n",
    "• Success Rate (≤1.5): {success_rates.get('success_rate_1.5', 0):.1%}\n",
    "\n",
    "Direction Accuracy:\n",
    "• Mean Direction Error: {error_metrics['mean_direction_error']:.1f}°\n",
    "\n",
    "Collision Prediction:\n",
    "• MAE: {collision_analysis['collision_prediction_mae']:.2f}\n",
    "• MSE: {collision_analysis['collision_prediction_mse']:.2f}\n",
    "\"\"\"\n",
    "    \n",
    "    axes[1,2].text(0.05, 0.95, summary_text, transform=axes[1,2].transAxes, \n",
    "                  fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                  bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[1,2].set_xlim(0, 1)\n",
    "    axes[1,2].set_ylim(0, 1)\n",
    "    axes[1,2].axis('off')\n",
    "    axes[1,2].set_title('Performance Summary')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model_comprehensive(model, test_loader, device='cpu', max_batches=20, save_dir='./evaluation_results/'):\n",
    "    \"\"\"Comprehensive model evaluation with intuitive metrics\"\"\"\n",
    "    import os\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Generating predictions...\")\n",
    "    predictions, targets, batch_info = predict_trajectories(model, test_loader, device, max_batches)\n",
    "    \n",
    "    print(\"Calculating error metrics...\")\n",
    "    error_metrics = calculate_position_error_metrics(predictions, targets)\n",
    "    \n",
    "    print(\"Calculating success rates...\")\n",
    "    success_rates = calculate_success_rates(predictions, targets)\n",
    "    \n",
    "    print(\"Analyzing collision prediction...\")\n",
    "    collision_analysis = analyze_collision_prediction(predictions, targets, batch_info)\n",
    "    \n",
    "    print(\"Creating visualizations...\")\n",
    "    plot_prediction_accuracy_analysis(error_metrics, success_rates, collision_analysis, \n",
    "                                    f\"{save_dir}/prediction_accuracy_analysis.png\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MODEL EVALUATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Mean Position Error: {error_metrics['mean_position_error']:.3f} grid units\")\n",
    "    print(f\"Median Position Error: {error_metrics['median_position_error']:.3f} grid units\")\n",
    "    print(f\"Success Rate (≤1.0 units): {success_rates.get('success_rate_1.0', 0):.1%}\")\n",
    "    print(f\"Success Rate (≤1.5 units): {success_rates.get('success_rate_1.5', 0):.1%}\")\n",
    "    print(f\"Mean Direction Error: {error_metrics['mean_direction_error']:.1f} degrees\")\n",
    "    print(f\"Collision Prediction MAE: {collision_analysis['collision_prediction_mae']:.3f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return {\n",
    "        'error_metrics': error_metrics,\n",
    "        'success_rates': success_rates,\n",
    "        'collision_analysis': collision_analysis\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
